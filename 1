 package com.mapreduce.classes;
 import java.io.IOException;
import java.util.Random;

 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.io.*;
 import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
 import org.apache.hadoop.mapreduce.*;
 import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;;
 
public class filterrecords {

    /**
     * @param args
     */
    
        public static class FilteringMapper extends Mapper<LongWritable, Text, Text,Text>{

            //private static final Logger _logger = Logger.getLogger(FilteringMapper.class);

            public void map(LongWritable key, Text value, Context context) {
                
                String record = value.toString();
                String[] s = record.split("\\|");
                String companyname = s[0];
                String productname = s[1];
                String size = s[2];
                String state = s[3];
                String pc = s[4];
                String price = s[5];
                if(!(("NA".equalsIgnoreCase(companyname))|| ("NA".equalsIgnoreCase(productname))))
                {
                    try {
                        context.write(new Text(),new Text(value));
                    } catch (IOException e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                    } catch (InterruptedException e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                    }
                }
            }
        }
        public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
             
                Configuration conf = new Configuration();
                       
                 @SuppressWarnings("deprecation")
                 
                   Job job = new Job(conf, "filterdata");
                   
                   job.setJarByClass(FilteringMapper.class);
                   
                   job.setOutputKeyClass(Text.class);
                   
                   job.setOutputValueClass(Text.class);
                       
                   job.setMapperClass(FilteringMapper.class);
                                          
                   job.setInputFormatClass(TextInputFormat.class);
                   
                   job.setOutputFormatClass(TextOutputFormat.class);
                       
                   FileInputFormat.addInputPath(job, new Path(args[0]));
                   
                   FileOutputFormat.setOutputPath(job, new Path(args[1]));
                       
                   job.waitForCompletion(true);
        }
    }
